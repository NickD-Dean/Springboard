{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c5b78d",
   "metadata": {},
   "source": [
    "# Predicting Box Office Revenue\n",
    "\n",
    "## Preprocessing and Training Notebook\n",
    "\n",
    "The purpose of this notebook is twofold:\n",
    "\n",
    "First I want to reduce the dimensionality of my data set in order to make the machine learning models I have to work with more tenable. Currently I have over 10,000 features and only 2,333 observations in the data set, causing serious computational slowdown for my models.  Further, at the time when this notebook was initially written the machine I'm working on didn't have the computational power to even create dummy variables from my 'cast' and 'crew' categories.  \n",
    "\n",
    "\n",
    "I plan to 'bin' categorical dummy variables into new features to reduce dimensionality.  This is relatively easy for features that are highly skewed (spoken language) or where each variable has a low frequency in the data set compared to 'None' (collection).  However I'll need to test performance on a basic linear/polynomial regressor for other categories where the data is exponentially skewed and there isn't a clear way to bin the data.  This will allow me to compare R^2 and Mean Absolute Percent Error metrics and determine which method for dimensionality reduction allows for the more accurate model. \n",
    "\n",
    "Finally, I'll use Lasso and Ridge regressors to test my initial linear regressor for overfit; additionally I'll be able to use the Lasso regressor coefficients to determine what features can be dropped to further reduce dimensionality and complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f82117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e146f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2333, 10456)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in CSV from EDA notebook\n",
    "\n",
    "boxoffice = pd.read_csv('../Data/boxoffice_EDA.csv', index_col=0, header=[0,1])\n",
    "boxoffice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080a6b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Genre</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Release_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 10456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                                                    \\\n",
       "  Action Adventure Animation Comedy Crime Documentary Drama Family Fantasy   \n",
       "0      0         0         0      1     0           0     1      1       0   \n",
       "1      0         0         0      0     0           0     1      0       0   \n",
       "2      0         1         1      0     0           0     0      1       0   \n",
       "\n",
       "           ... Release_month                             \n",
       "  Foreign  ...             3  4  5  6  7  8  9 10 11 12  \n",
       "0       0  ...             0  0  0  0  0  1  0  0  0  0  \n",
       "1       0  ...             0  0  0  0  0  0  0  1  0  0  \n",
       "2       0  ...             0  0  0  0  0  1  0  0  0  0  \n",
       "\n",
       "[3 rows x 10456 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxoffice.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57db9da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genre', 'Collection', 'Company', 'Country', 'Spoken_lang', 'Keywords',\n",
       "       'Descriptive', 'Numerical', 'Release_year', 'Release_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying names of top level of multi-index for later reference\n",
    "boxoffice.columns.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c4776",
   "metadata": {},
   "source": [
    "## Binning Categorical Data\n",
    "\n",
    "To begin I want to significantly cut down on the number of features that I have in the data set.  By far the largest category that I have is Keywords, however the distribution of that category and several others presents several options for binning my data.  I can bin them into quartiles by either frequency or median/mean revenue in the data set. \n",
    "\n",
    "However I do have several feature categories that I won't be touching: Genre, Release_year, Country, and Release_month.  These categories all have fewer than 70 individual features.  Additionally I have a compelling reason to believe that each of these will have a large impact on revenue.  Genre, Release_year, and Release_month all were significantly more evenly distributed across films than other categories.  For these three categories median revenue was also skewed towards certain sub-categories which indicates that they have an impact revenue.  \n",
    "\n",
    "While the Country category is **heavily** skewed towards films made in the United States, revenue is heavily skewed towards more 'exotic' countries.  This is likely a result of blockbuster films like 'Pirates of the Carribean' or 'The Avengers' being filmed on site in other locations.  I suspect that this category will be highly correlated with budget and may be dropped after I check Lasso regresor coefficients.  Regardless, this category only has 67 sub-categories and consolidating those into fewer bins will lose what appears to be useful information with minimal impact on reducing the 10,456 dimensions that the data set currently has.\n",
    "\n",
    "This means that I need to bin the Spoken_lang, Company, Keywords, and Collection columns.  Later I'll come back through and treat the Cast and Crew categories the same as the Keyword category once I have access to a machine with enough RAM to handle those categories. \n",
    "\n",
    "The best place for me to start with binning is going to be the Spoken_lang category since it's highly skewed towards the 'English' sub-category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4066f21",
   "metadata": {},
   "source": [
    "#### Binning Spoken_lang\n",
    "\n",
    "Based on the work from my EDA notebook the 'English' sub-category accounts for 2,180 films in this data set.  It's clear that the simplest way to bin this category is to reduce it to a single column that indicates if a film's primary language is English or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad84127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of column lables to be dropped\n",
    "dropped = list(boxoffice['Spoken_lang'].columns)\n",
    "dropped.remove('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b295f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to iterate over the dropped list and remove all languages from Spoken_lang other than english\n",
    "for col in dropped:\n",
    "    boxoffice.drop(col, level=1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46785a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   English\n",
       "0        1\n",
       "1        1\n",
       "2        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that English is the only remaining column\n",
    "boxoffice.Spoken_lang.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dca544",
   "metadata": {},
   "source": [
    "#### Binning Film Collection dummy variables\n",
    "\n",
    "Ultimately this was going to be relatively complex with the multi-indexed dataframe so I went back to my EDA notebook and created a boolean column that indicates if a film belongs to a collection or not.  The final step is to transform this into the value for 1 or 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70b108f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "Name: (Descriptive, Collection), dtype: int32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting the column in question to a numeric data type\n",
    "boxoffice['Descriptive', 'Collection'] = boxoffice['Descriptive', 'Collection'].astype('int')\n",
    "boxoffice['Descriptive', 'Collection'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23383a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pinocchio and the Emperor of the Night</td>\n",
       "      <td>Pinocchio and his friends, a glow worm and a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pinocchio and the Emperor of the Night</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             original_title  \\\n",
       "0  The Princess Diaries 2: Royal Engagement   \n",
       "1                                  Whiplash   \n",
       "2    Pinocchio and the Emperor of the Night   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Mia Thermopolis is now a college graduate and ...   \n",
       "1  Under the direction of a ruthless instructor, ...   \n",
       "2  Pinocchio and his friends, a glow worm and a m...   \n",
       "\n",
       "                                             tagline  \\\n",
       "0  It can take a lifetime to find true love; she'...   \n",
       "1    The road to greatness can take you to the edge.   \n",
       "2                                                NaN   \n",
       "\n",
       "                                      title  Collection  \n",
       "0  The Princess Diaries 2: Royal Engagement           1  \n",
       "1                                  Whiplash           0  \n",
       "2    Pinocchio and the Emperor of the Night           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxoffice['Descriptive'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e6aece",
   "metadata": {},
   "source": [
    "While I'm working on this column in Descriptive I'm also going to drop the overview, tagline, and original_title columns, and set the index to the title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff27662",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxoffice.drop('overview', level=1, axis=1, inplace=True)\n",
    "boxoffice.drop('tagline', level=1, axis=1, inplace=True)\n",
    "boxoffice.drop('original_title', level=1, axis=1, inplace=True)\n",
    "# Storing the titles in a seperate Series for later use as needed\n",
    "Titles = boxoffice['Descriptive', 'title']\n",
    "boxoffice.drop('title', level=1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dee8e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Collection\n",
       "0           1\n",
       "1           0\n",
       "2           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify that the Descriptive category has been reduced to only the one-hot encoded column for collections\n",
    "boxoffice['Descriptive'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5e5a46",
   "metadata": {},
   "source": [
    "## Testing the accuracy of linear regression with the data set as is\n",
    "\n",
    "At this point I have a huge number of columns, and I haven't made significant reductions in the number of features yet. \n",
    "\n",
    "However once I've binned the Company and Keyword columns I'll have eliminated thousands of features.  Prior to doing this I want to get a baseline for how accurate a model is with all of these columns left in the data set. \n",
    "\n",
    "The reason that this is important to do now, prior to reducing the dimensionality of the Company and Keywords categories is that each movie has multiple companies and keywords associated with it, while there is only a single language and film collection for each movie.  Reducing the Spoken_lang and Collection categories isn't eliminating complex information about each film like binning the Company and Keywords categories will be, since each film can have multiple companies or keywords, but only a single film collection or spoken language.\n",
    "\n",
    "Once I have a baseline of performance with the entire dataset using a dummy regressor as well as a general linear regression model with only the numerical data; I'll build up complexity by adding in additional categorical data to assess which provides the best performance. The purpose of building my dataset is to help identify at which point overfitting becomes a problem and decide if, and to what degree, I need to simplify several categories of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28d37f",
   "metadata": {},
   "source": [
    "### Train / Test Split\n",
    "\n",
    "Here I plan to create a train / test split that I'll work with for the remainder of this notebook, and test the accuracy of my best models/data at the end to assess model performance prior to attempting different regression models in the subsequent notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86efbee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating out the target variable\n",
    "y = boxoffice['Numerical', 'revenue']\n",
    "X = boxoffice.drop('revenue', level=1, axis=1)\n",
    "# Scaling the numerical data in X \n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X['Numerical'])\n",
    "X['Numerical'] = scaler.transform(X['Numerical'])\n",
    "# Creating train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a13bcc",
   "metadata": {},
   "source": [
    "## Checking performance of a dummy regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82508da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.49674973e+08]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reg = DummyRegressor(strategy='mean')\n",
    "mean_reg.fit(X_train, y_train)\n",
    "mean_reg.constant_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0657665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predictor mape score:  3227.6859999999997\n",
      "Mean predictor r^2 score:  0.0\n",
      "Mean predictor rmse score:  179819930.675\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the mean with mean absolute percent error, R-squared, and root mean squared error\n",
    "pred = mean_reg.predict(X_train)\n",
    "MAPE_mean = round(mean_absolute_percentage_error(y_train, pred), 5)*100\n",
    "R2_mean = round(r2_score(y_train, pred), 5)\n",
    "RMSE_mean = round(mean_squared_error(y_train, pred, squared=False), 5)\n",
    "print('Mean predictor mape score: ', MAPE_mean)\n",
    "print('Mean predictor r^2 score: ', R2_mean)\n",
    "print('Mean predictor rmse score: ', RMSE_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a82f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176693296.3539534"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f33fb1",
   "metadata": {},
   "source": [
    "*This block of code will be reproduced for each iteration of the linear regression model.  At the end of this notebook I'll be able to evaluate the scoring metrics side by side and take note of any patterns.*\n",
    "\n",
    "It seems that the mean revenue is not a strong predictor, which is reasonable.  The smallest value in my target variable is around 5,000 USD, and the largest is over 1.5 Billion USD - a significant jump in revenue to the point where the mean value is actually less than 10% of the largest revenue value.  At the same time the mean revenue for this data set is 2,500% of the smallest value.  There is ***significant*** variability in the target metric for this business problem, which means that I'll need to decide ahead of time what a 'good' metric score will mean.  \n",
    "\n",
    "Given that at it's core, this problem is about predicting human behavior (purchasing of movie tickets), an R-Squared value of 0.5 will be considered 'good'.  This is something that has been cited in multiple blogs online as a good score for predicting human behavior, such as [Jim Frost's blog.](https://statisticsbyjim.com/regression/interpret-r-squared-regression/)\n",
    "\n",
    "Given the huge variability around the mean, and what will be resultingly large mean % error and root-mean-squared errors I think that it's prudent to consider any RMSE score that is less than or equal to one standard deviation as 'good' for now.  Since I'll be saving all of these scores and comparing them at the end of this notebook I'll use that as a standard to make initial judements on as I work to that point.  \n",
    "\n",
    "Mean absolute percentage error is going to be a strong measure of how accurate the model is given the massive scale I'm working with, I'm not sure what I could even call a 'good' MAPE score.  Having run some initial models in a scratch notebook (appended in GitHub), and seeing how the dummy regressor using the mean performs here I believe that any MAPE score less than 1000% should be considered passable, and that anything less than 500% should be considered good. \n",
    "\n",
    "At the end of this notebook I'll be able to identify a subset(s) of my data that will allow a linear regression model to achieve these scores:\n",
    "\n",
    "***R-squared: 0.5***\n",
    "\n",
    "***MAPE: 500%***\n",
    "\n",
    "***RMSE: 176,693,296 USD***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ac1dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263196dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b020913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69070f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0728e3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7127d2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a00c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e905e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9106a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c8109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97061d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010bcef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a261289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec67b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbbc4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c701b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba97cf94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05cef7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838cb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ad1043",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfdd160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dfb7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef0031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092060ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
