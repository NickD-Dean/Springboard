{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "665273ef",
   "metadata": {},
   "source": [
    "# Predicting Box Office Revenue\n",
    "\n",
    "## Preprocessing and Training Notebook\n",
    "\n",
    "The purpose of this notebook is twofold:\n",
    "\n",
    "First I want to reduce the dimensionality of my data set in order to make the machine learning models I have to work with more tenable. Currently I have over 10,000 features and only 2,333 observations in the data set, causing serious computational slowdown for my models.  Further, at the time when this notebook was initially written the machine I'm working on didn't have the computational power to even create dummy variables from my 'cast' and 'crew' categories.  \n",
    "\n",
    "\n",
    "I plan to 'bin' categorical dummy variables into new features to reduce dimensionality.  This is relatively easy for features that are highly skewed (spoken language) or where each variable has a low frequency in the data set compared to 'None' (collection).  However I'll need to test performance on a basic linear/polynomial regressor for other categories where the data is exponentially skewed and there isn't a clear way to bin the data.  This will allow me to compare R^2 and Mean Absolute Percent Error metrics and determine which method for dimensionality reduction allows for the more accurate model. \n",
    "\n",
    "Finally, I'll use Lasso and Ridge regressors to test my initial linear regressor for overfit; additionally I'll be able to use the Lasso regressor coefficients to determine what features can be dropped to further reduce dimensionality and complexity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d718d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, r2_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211c3f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2333, 10456)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in CSV from EDA notebook\n",
    "\n",
    "boxoffice = pd.read_csv(r'C:\\Users\\deann\\Documents\\Data\\Box Office Prediction Data\\boxoffice_EDA.csv', index_col=0, \n",
    "                        header=[0,1])\n",
    "\n",
    "boxoffice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8254e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">Genre</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">Release_month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 10456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Genre                                                                    \\\n",
       "  Action Adventure Animation Comedy Crime Documentary Drama Family Fantasy   \n",
       "0      0         0         0      1     0           0     1      1       0   \n",
       "1      0         0         0      0     0           0     1      0       0   \n",
       "2      0         1         1      0     0           0     0      1       0   \n",
       "\n",
       "           ... Release_month                             \n",
       "  Foreign  ...             3  4  5  6  7  8  9 10 11 12  \n",
       "0       0  ...             0  0  0  0  0  1  0  0  0  0  \n",
       "1       0  ...             0  0  0  0  0  0  0  1  0  0  \n",
       "2       0  ...             0  0  0  0  0  1  0  0  0  0  \n",
       "\n",
       "[3 rows x 10456 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxoffice.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f027becb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Genre', 'Collection', 'Company', 'Country', 'Spoken_lang', 'Keywords',\n",
       "       'Descriptive', 'Numerical', 'Release_year', 'Release_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying names of top level of multi-index for later reference\n",
    "boxoffice.columns.get_level_values(0).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5dbf1f",
   "metadata": {},
   "source": [
    "## Binning Categorical Data\n",
    "\n",
    "To begin I want to significantly cut down on the number of features that I have in the data set.  By far the largest category that I have is Keywords, however the distribution of that category and several others presents several options for binning my data.  I can bin them into quartiles by either frequency or median/mean revenue in the data set. \n",
    "\n",
    "However I do have several feature categories that I won't be touching: Genre, Release_year, Country, and Release_month.  These categories all have fewer than 70 individual features.  Additionally I have a compelling reason to believe that each of these will have a large impact on revenue.  Genre, Release_year, and Release_month all were significantly more evenly distributed across films than other categories.  For these three categories median revenue was also skewed towards certain sub-categories which indicates that they have an impact revenue.  \n",
    "\n",
    "While the Country category is **heavily** skewed towards films made in the United States, revenue is heavily skewed towards more 'exotic' countries.  This is likely a result of blockbuster films like 'Pirates of the Carribean' or 'The Avengers' being filmed on site in other locations.  I suspect that this category will be highly correlated with budget and may be dropped after I check Lasso regresor coefficients.  Regardless, this category only has 67 sub-categories and consolidating those into fewer bins will lose what appears to be useful information with minimal impact on reducing the 10,456 dimensions that the data set currently has.\n",
    "\n",
    "This means that I need to bin the Spoken_lang, Company, Keywords, and Collection columns.  Later I'll come back through and treat the Cast and Crew categories the same as the Keyword category once I have access to a machine with enough RAM to handle those categories. \n",
    "\n",
    "The best place for me to start with binning is going to be the Spoken_lang category since it's highly skewed towards the 'English' sub-category.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5bfd11",
   "metadata": {},
   "source": [
    "#### Binning Spoken_lang\n",
    "\n",
    "Based on the work from my EDA notebook the 'English' sub-category accounts for 2,180 films in this data set.  It's clear that the simplest way to bin this category is to reduce it to a single column that indicates if a film's primary language is English or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72327e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of column lables to be dropped\n",
    "dropped = list(boxoffice['Spoken_lang'].columns)\n",
    "dropped.remove('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c68c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to iterate over the dropped list and remove all languages from Spoken_lang other than english\n",
    "\n",
    "for col in dropped:\n",
    "    boxoffice.drop(col, level=1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8585eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   English\n",
       "0        1\n",
       "1        1\n",
       "2        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that English is the only remaining column\n",
    "boxoffice.Spoken_lang.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d135ae",
   "metadata": {},
   "source": [
    "#### Binning Film Collection dummy variables\n",
    "\n",
    "Ultimately this was going to be relatively complex with the multi-indexed dataframe so I went back to my EDA notebook and created a boolean column that indicates if a film belongs to a collection or not.  The final step is to transform this into the value for 1 or 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a47f5a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "Name: (Descriptive, Collection), dtype: int32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting the column in question to a numeric data type\n",
    "boxoffice['Descriptive', 'Collection'] = boxoffice['Descriptive', 'Collection'].astype('int')\n",
    "boxoffice['Descriptive', 'Collection'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f24bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>Collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>Mia Thermopolis is now a college graduate and ...</td>\n",
       "      <td>It can take a lifetime to find true love; she'...</td>\n",
       "      <td>The Princess Diaries 2: Royal Engagement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>Under the direction of a ruthless instructor, ...</td>\n",
       "      <td>The road to greatness can take you to the edge.</td>\n",
       "      <td>Whiplash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pinocchio and the Emperor of the Night</td>\n",
       "      <td>Pinocchio and his friends, a glow worm and a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pinocchio and the Emperor of the Night</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             original_title  \\\n",
       "0  The Princess Diaries 2: Royal Engagement   \n",
       "1                                  Whiplash   \n",
       "2    Pinocchio and the Emperor of the Night   \n",
       "\n",
       "                                            overview  \\\n",
       "0  Mia Thermopolis is now a college graduate and ...   \n",
       "1  Under the direction of a ruthless instructor, ...   \n",
       "2  Pinocchio and his friends, a glow worm and a m...   \n",
       "\n",
       "                                             tagline  \\\n",
       "0  It can take a lifetime to find true love; she'...   \n",
       "1    The road to greatness can take you to the edge.   \n",
       "2                                                NaN   \n",
       "\n",
       "                                      title  Collection  \n",
       "0  The Princess Diaries 2: Royal Engagement           1  \n",
       "1                                  Whiplash           0  \n",
       "2    Pinocchio and the Emperor of the Night           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxoffice['Descriptive'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d5e18",
   "metadata": {},
   "source": [
    "While I'm working on this column in Descriptive I'm also going to drop the overview, tagline, and original_title columns, and set the index to the title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198b98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxoffice.drop('overview', level=1, axis=1, inplace=True)\n",
    "boxoffice.drop('tagline', level=1, axis=1, inplace=True)\n",
    "boxoffice.drop('original_title', level=1, axis=1, inplace=True)\n",
    "# Storing the titles in a seperate Series for later use as needed\n",
    "Titles = boxoffice['Descriptive', 'title']\n",
    "boxoffice.drop('title', level=1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f9dea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Collection\n",
       "0           1\n",
       "1           0\n",
       "2           0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verify that the Descriptive category has been reduced to only the one-hot encoded column for collections\n",
    "boxoffice['Descriptive'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0427a1c5",
   "metadata": {},
   "source": [
    "## Testing the accuracy of linear regression with the data set as is\n",
    "\n",
    "At this point I have a huge number of columns, and I haven't made significant reductions in the number of features yet. \n",
    "\n",
    "However once I've binned the Company and Keyword columns I'll have eliminated thousands of features.  Prior to doing this I want to get a baseline for how accurate a model is with all of these columns left in the data set. \n",
    "\n",
    "The reason that this is important to do now, prior to reducing the dimensionality of the Company and Keywords categories is that each movie has multiple companies and keywords associated with it, while there is only a single language and film collection for each movie.  Reducing the Spoken_lang and Collection categories isn't eliminating complex information about each film like binning the Company and Keywords categories will be. \n",
    "\n",
    "This will also give me a baseline of accuracy prior to scaling the numeric data that I have to work with as well.\n",
    "\n",
    "If the model takes excessively long to train I'll be forced to trim a lot of those columns from my data set, so I'll need to take the time required to run and print that as well as test the accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8111836c",
   "metadata": {},
   "source": [
    "#### Renaming columns in Release_month\n",
    "\n",
    "While working with dummy variables I think that it's wise to rename the columns for Release_month since it's possible that I'll be dropping the hierarchical index before creating a train/test split and training my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1c3e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jan</th>\n",
       "      <th>Feb</th>\n",
       "      <th>Mar</th>\n",
       "      <th>Apr</th>\n",
       "      <th>May</th>\n",
       "      <th>June</th>\n",
       "      <th>July</th>\n",
       "      <th>Aug</th>\n",
       "      <th>Sep</th>\n",
       "      <th>Oct</th>\n",
       "      <th>Nov</th>\n",
       "      <th>Dec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Jan  Feb  Mar  Apr  May  June  July  Aug  Sep  Oct  Nov  Dec\n",
       "0    0    0    0    0    0     0     0    1    0    0    0    0\n",
       "1    0    0    0    0    0     0     0    0    0    1    0    0\n",
       "2    0    0    0    0    0     0     0    1    0    0    0    0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months ={'1':'Jan', '2':'Feb', '3':'Mar', '4':'Apr', '5':'May', '6':'June', \n",
    "         '7':'July', '8':'Aug', '9':'Sep', '10':'Oct', '11':'Nov', '12':'Dec'}\n",
    "boxoffice.rename(columns=months, level=1, inplace=True)\n",
    "boxoffice['Release_month'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1234433e",
   "metadata": {},
   "source": [
    "#### Creating the train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cb354c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    134734481.0\n",
       "1     48982041.0\n",
       "2      3418605.0\n",
       "Name: (Numerical, revenue), dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = boxoffice['Numerical', 'revenue']\n",
    "y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f2fe378",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boxoffice.drop('revenue', level=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ac5e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ff4547",
   "metadata": {},
   "source": [
    "#### Evaluating the mean as a predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d2cdaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.49246951e+08]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_reg = DummyRegressor(strategy='mean')\n",
    "mean_reg.fit(X_train, y_train)\n",
    "mean_reg.constant_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b335152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predictor mape score:  2288.4\n",
      "Mean predictor r^2 score:  -0.00113\n",
      "Mean predictor rmse score:  167013048.70898\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the mean with mean absolute percent error, R-squared, and root mean squared error\n",
    "pred = mean_reg.predict(X_test)\n",
    "MAPE_mean = round(mean_absolute_percentage_error(y_test, pred), 3)*100\n",
    "R2_mean = round(r2_score(y_test, pred), 5)\n",
    "RMSE_mean = round(mean_squared_error(y_test, pred, squared=False), 5)\n",
    "\n",
    "print('Mean predictor mape score: ', MAPE_mean)\n",
    "print('Mean predictor r^2 score: ', R2_mean)\n",
    "print('Mean predictor rmse score: ', RMSE_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52757054",
   "metadata": {},
   "source": [
    "#### Testing the model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dbd002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_1 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba53575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train:  4.283\n"
     ]
    }
   ],
   "source": [
    "# Training the first regressor and noting the time it takes to train\n",
    "train_start = time.time()\n",
    "linear_1.fit(X_train, y_train)\n",
    "train1_finish = time.time()\n",
    "print('Time to train: ', str(round(train1_finish-train_start, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e0ed287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test mape scpre:  675.9000000000001\n",
      "Baseline test R^2 score:  0.39158\n",
      "Baseline test rmse score:  130199031.78982\n"
     ]
    }
   ],
   "source": [
    "# predicting new values with the first regressor\n",
    "preds = linear_1.predict(X_test)\n",
    "\n",
    "# calculating R^2 and Mean Absolute Percentage Error\n",
    "MAPE_1 = round(mean_absolute_percentage_error(y_test, preds), 3)*100\n",
    "R2_1 = round(r2_score(y_test, preds), 5)\n",
    "RMSE_1 = round(mean_squared_error(y_test, preds, squared=False), 5)\n",
    "\n",
    "print('Baseline test mape scpre: ', MAPE_1)\n",
    "print('Baseline test R^2 score: ', R2_1)\n",
    "print('Baseline test rmse score: ', RMSE_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabc943c",
   "metadata": {},
   "source": [
    "Here it's clear that my initial model is not all that accurate from the R^2 score.  Additionally, my model is off on revenue prediction by 680% on average, which indicates to me that the baseline linear regression model here is an 'accurate guess' at revenue.  \n",
    "\n",
    "It's not clear from this whether the low scores are a result of overfitting, or because I need to choose a different model for this data set.  Prior to moving forward I need to determine how well the model can predict using only the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28a483bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline training mape scpre:  0.0\n",
      "Baseline training R^2 score:  1.0\n",
      "Baseline training rmse score:  21.62357\n"
     ]
    }
   ],
   "source": [
    "# To get a sense for overfit I also want to see how well the model performs on the training data\n",
    "\n",
    "train_preds = linear_1.predict(X_train)\n",
    "\n",
    "MAPE = round(mean_absolute_percentage_error(y_train, train_preds), 3)*100\n",
    "R2 = round(r2_score(y_train, train_preds), 5)\n",
    "RMSE = round(mean_squared_error(y_train, train_preds, squared=False), 5)\n",
    "\n",
    "print('Baseline training mape score: ', MAPE)\n",
    "print('Baseline training R^2 score: ', R2)\n",
    "print('Baseline training rmse score: ', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d13fda",
   "metadata": {},
   "source": [
    "It appears that the issue is that the model is too complex and overfitted to the training data.  I have several options to remedy this but the first step I can take is to reduce the number of features that I have significantly.  \n",
    "\n",
    "At this point I have several options.  Currently I can bin the production companies and keywords categories into fewer features, and later I'll have access to the cast & crew information as well.  From a business perspective, when a studio is presented a film as an option to invest in they control who is cast in the film, who works on it's crew, and which other studios they collaborate with.  What they don't have control over when presented with a script is what the story **is** - it's already been written.  If the core story of a film is not worth much, then it doesn't make sense to sink additional resources into a quality cast/crew, high-value filming on location in other countries, or collaboration with other studios.   \n",
    "\n",
    "There are several features that can be used to characterize a story which are immutable about that film.  One is whether it's part of a larger story - a collection - or not. Another feature that a studio has no control over is what genre a film is, if the screenwriter has written a thriller film it's rather difficult to change that into a romantic-comedy.  Finally, there are keywords that can describe a film's nature as well.  Films about detectives and murder can't easily be changed into family-friendly animation movies.  \n",
    "\n",
    "I've already reduced the dimensionality of the collections category to 1, and the genres category is small enough that I don't see reducing it's dimensionality as effective.  I either need to strip the keywords category down to a few features or eliminate it entirely.  \n",
    "\n",
    "My instinct is to drop the category in it's entirety, and see how that affects the performance metrics.  The most frequently appearing keywords only appear in 188 films, and the top three most frequen keywords all indicate that a film is part of a larger film collection.  The other frequently occuring keywords indicate if there is a female director for a film, and if the film involves a murder.  All of these features of a film are represented in some way by other categories that the data set contains.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95108d42",
   "metadata": {},
   "source": [
    "#### Testing a linear model on only numeric data\n",
    "\n",
    "Before I spend time dropping categorical data to test how that affects the performance of linear models and overfit I want to see if working with only the numerical data in the dataset is more accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "906977cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Num = boxoffice['Numerical']\n",
    "y=Num['revenue']\n",
    "X=Num.drop('revenue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cce009f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train:  0.014\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "lin_num = LinearRegression()\n",
    "start_time = time.time()\n",
    "lin_num.fit(X_train, y_train)\n",
    "finish_num_time = time.time()\n",
    "print('Time to train: ', str(round(finish_num_time-start_time, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0101a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical test mape score:  468.9\n",
      "Numerical test r^2 score:  0.49182\n",
      "Numerical test rmse score:  118991518.84164\n"
     ]
    }
   ],
   "source": [
    "pred = lin_num.predict(X_test)\n",
    "MAPE_num = round(mean_absolute_percentage_error(y_test, pred), 3)*100\n",
    "R2_num = round(r2_score(y_test, pred), 5)\n",
    "RMSE_num = round(mean_squared_error(y_test, pred, squared=False), 5)\n",
    "\n",
    "print('Numerical test mape score: ', MAPE_num)\n",
    "print('Numerical test r^2 score: ', R2_num)\n",
    "print('Numerical test rmse score: ', RMSE_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1e57cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical train mape score:  1198.8\n",
      "Numerical train r^2 score:  0.51871\n",
      "Numerical train rmse score:  124747627.03442\n"
     ]
    }
   ],
   "source": [
    "train_pred = lin_num.predict(X_train)\n",
    "MAPE = round(mean_absolute_percentage_error(y_train, train_pred), 3)*100\n",
    "R2 = round(r2_score(y_train, train_pred), 5)\n",
    "RMSE = round(mean_squared_error(y_train, train_pred, squared=False), 5)\n",
    "\n",
    "print('Numerical train mape score: ', MAPE)\n",
    "print('Numerical train r^2 score: ', R2)\n",
    "print('Numerical train rmse score: ', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8a81fb",
   "metadata": {},
   "source": [
    "#### Checking to see how frequent keywords appear in the data set\n",
    "\n",
    "I want to see if there's a convenient place where I could bin this category based on how often keywords appear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e529018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2333, 7134)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prior to just dropping all 7,000+ features I want to double check the distribution of the Keywords\n",
    "\n",
    "#create a new data frame of the keywords category\n",
    "kwords = boxoffice['Keywords']\n",
    "count = kwords.apply(pd.value_counts)\n",
    "x = list(kwords.columns)\n",
    "y = count.iloc[1]\n",
    "kwords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06460da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all keywords that appear more than 5 times in the data set\n",
    "y = y.sort_values(ascending=False)\n",
    "z = y[y >= 5]\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a7d67",
   "metadata": {},
   "source": [
    "Roughly 1 in every 7 of all keywords appear in at least **five** films - the majority of these features are not useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceededdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how many keywords appear in at least 50 films\n",
    "k = z[z >= 50]\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b34b4",
   "metadata": {},
   "source": [
    "Only 23 of the 7,134 keywords actually appear in 50 or more films.  Five of those keywords indicate that a film is part of a collection, another ten can easily be mapped to genres, and two indicate the filming location.  I'm going to drop the keywords data.  It's not worth binning the keywords with the distribution among films being so extreme, if this dramatically affects the model's accuracy I can always add these 23 columns back into the data set from the kwords data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6241b0",
   "metadata": {},
   "source": [
    "#### Testing how a linear regression model works on scaled data set\n",
    "\n",
    "Before I test the model on a smaller data set I need to scale the numeric data since in my final models I'll only be using scaled data.  In order to get an accurate idea of how removing different parts of the data will alter model performance I need to be comparing metrics to how it performs on the entire data set with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd18acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=boxoffice['Numerical', 'revenue']\n",
    "X=boxoffice.drop('revenue', level=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling the numerical data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X['Numerical'])\n",
    "X['Numerical'] = scaler.transform(X['Numerical'])\n",
    "X['Numerical'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebb4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3805a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3609c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_2 = LinearRegression()\n",
    "train_start = time.time()\n",
    "linear_2.fit(X_train, y_train)\n",
    "train2_finish = time.time()\n",
    "print('Time to train: ', str(round(train2_finish-train_start, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461cd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_preds = linear_2.predict(X_test)\n",
    "MAPE_2 = mean_absolute_percentage_error(y_test, scaled_preds)\n",
    "R2_2 = r2_score(y_test, scaled_preds)\n",
    "RMSE_2 = mean_squared_error(y_test, scaled_preds, squared=False)\n",
    "\n",
    "print('Scaled test mape scpre: ', MAPE_2)\n",
    "print('Scaled test R^2 score: ', R2_2)\n",
    "print('Scaled test rmse score: ', RMSE_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a354ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_preds = linear_2.predict(X_train)\n",
    "MAPE = mean_absolute_percentage_error(y_train, scaled_train_preds)\n",
    "R2 = r2_score(y_train, scaled_train_preds)\n",
    "RMSE = mean_squared_error(y_train, scaled_train_preds, squared=False)\n",
    "\n",
    "print('Scaled train mape scpre: ', MAPE)\n",
    "print('Scaled train R^2 score: ', R2)\n",
    "print('Scaled train rmse score: ', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0682a36d",
   "metadata": {},
   "source": [
    "## Testing performance of linear models after reducing dimensionality of the data\n",
    "\n",
    "The first step here as outlined above, is to test performance on a data set that has had the keywords category eliminated.  I'll also compare these results to those that come after removing the company data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc0675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step here is to scale the entire dataset with a scaler that is fit to the whole datasetrather than just the train & test split data. \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(boxoffice['Numerical'])\n",
    "boxoffice['Numerical'] = scaler.transform(boxoffice['Numerical'])\n",
    "boxoffice['Numerical'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cdf306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe without the Keywords categories\n",
    "trimmed = boxoffice.drop('Keywords', level=0, axis=1)\n",
    "trimmed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabb442",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trimmed['Numerical', 'revenue']\n",
    "X = trimmed.drop('revenue', level=1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91795bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_3 = LinearRegression()\n",
    "train_start = time.time()\n",
    "linear_3.fit(X_train, y_train)\n",
    "train3_finish = time.time()\n",
    "print('Time to train: ', str(round(train3_finish-train_start, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linear_3.predict(X_test)\n",
    "\n",
    "MAPE_3 = mean_absolute_percentage_error(y_test, preds)\n",
    "R2_3 = r2_score(y_test, preds)\n",
    "RMSE_3 = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print('Trimmed & scaled test mape scpre: ', MAPE_3)\n",
    "print('Trimmed & scaled test R^2 score: ', R2_3)\n",
    "print('Trimmed & scaled test rmse score: ', RMSE_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = linear_3.predict(X_train)\n",
    "\n",
    "MAPE = mean_absolute_percentage_error(y_train, train_preds)\n",
    "R2 = r2_score(y_train, train_preds)\n",
    "RMSE = mean_squared_error(y_train, train_preds)\n",
    "\n",
    "print('Trimmed & scaled train mape score: ', MAPE)\n",
    "print(\"Trimmed & scaled train R^2 score: \", R2)\n",
    "print('Trimmed & scaled train rmse score: ', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b00d0",
   "metadata": {},
   "source": [
    "Based off of this it would appear that the Keywords category has a significant impact on the ability of my model to generalize to unseen data, and on a linear regression model's ability to predict the correct results on even the training data. \n",
    "\n",
    "Next it will be useful to see how a linear regression model performs without the company data as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1083e308",
   "metadata": {},
   "source": [
    "#### Testing linear regression with no company data\n",
    "\n",
    "This drops 2,748 of the features in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d53e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trimmed2 = boxoffice.drop('Company', level=0, axis=1)\n",
    "Trimmed2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2927b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double checking to make sure that the numerical data is still scaled\n",
    "Trimmed2['Numerical'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af6e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=Trimmed2['Numerical', 'revenue']\n",
    "X=Trimmed2.drop('revenue', level=1, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276df537",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_4 = LinearRegression()\n",
    "train_start=time.time()\n",
    "linear_4.fit(X_train, y_train)\n",
    "train4_finish=time.time()\n",
    "print('Time to train: ', str(round(train4_finish-train_start, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f041102",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = linear_4.predict(X_test)\n",
    "\n",
    "MAPE_4 = mean_absolute_percentage_error(y_test, preds)\n",
    "R2_4 = r2_score(y_test, preds)\n",
    "RMSE_4 = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print('No company data mape test score: ', MAPE_4)\n",
    "print('No company data R^2 test score: ', R2_4)\n",
    "print('No company data rmse test score: ', RMSE_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8937e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = linear_4.predict(X_train)\n",
    "\n",
    "MAPE = mean_absolute_percentage_error(y_train, train_preds)\n",
    "R2 = r2_score(y_train, train_preds)\n",
    "RMSE = mean_squared_error(y_train, train_preds, squared=False)\n",
    "\n",
    "print('No company data mape train score: ', MAPE)\n",
    "print('No company data, R^2 train score: ', R2)\n",
    "print('No company data rmse train score: ', RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3323e5",
   "metadata": {},
   "source": [
    "After training and examining the metrics for 4 different linear regression models it seems that this isn't the best model for this problem.  Moving forward I'm going to evaluate Lasso and Ridge regressors to check for overfit. \n",
    "\n",
    "It is notable that the linear regression model on the data set without the company data had the smallest mean percent and root mean squared error of all the models, however the R-squared metric was almost zero, which is troubling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d1512a",
   "metadata": {},
   "source": [
    "## Testing Lasso regression model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cb39aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I want to get a baseline level of performance for a model to compare to. \n",
    "lasso_5 = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boxoffice['Numerical', 'revenue']\n",
    "X = boxoffice.drop('revenue', level=1, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb0f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = time.time()\n",
    "lasso_5.fit(X_train, y_train)\n",
    "train5_finish = time.time()\n",
    "print('Time to train: ', str(round(train5_finish-train_start, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808b8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lasso_5.predict(X_test)\n",
    "MAPE_5 = mean_absolute_percentage_error(y_test, preds)\n",
    "R2_5 = r2_score(y_test, preds)\n",
    "RMSE_5 = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "print('Baseline lasso test mape score: ', MAPE_5)\n",
    "print('Baseline lasso test r^2 score: ', R2_5)\n",
    "print('Baseline lasso test rmse score: ', RMSE_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efea755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = lasso_5.predict(X_train)\n",
    "MAPE = mean_absolute_percentage_error(y_train, train_preds)\n",
    "R2 = r2_score(y_train, train_preds)\n",
    "RMSE = mean_squared_error(y_train, train_preds, squared=False)\n",
    "\n",
    "print('Baseline lasso train mape score: ', MAPE)\n",
    "print('Baseline lasso train r^2 score: ', R2)\n",
    "print('Baseline lasso train rmse score: ', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311883a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba107ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcbaa90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf12ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988add8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e726f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
